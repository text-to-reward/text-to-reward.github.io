<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Dense Reward Generation For Robot Learning">
  <meta name="keywords" content="Robot Learning, Large Langauge Model, Code Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/franka.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://www.xlang.ai/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://yale-lily.github.io/spider">
            Spider
          </a>
          <a class="navbar-item" href="https://github.com/HKUNLP/UnifiedSKG">
            UnifiedSKG
          </a>
          <a class="navbar-item" href="https://github.com/Yushi-Hu/IC-DST">
            IC-DST
          </a>
          <a class="navbar-item" href="https://github.com/HKUNLP/icl-selective-annotation">
            Selective Annotation
          </a>
          <a class="navbar-item" href="https://ds1000-code-gen.github.io/">
            DS-1000
          </a>
          <a class="navbar-item" href="https://instructor-embedding.github.io/">
            Instructor
          </a>
          <a class="navbar-item" href="https://lm-code-binder.github.io/">
            Binder
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tianbaoxie.com/">Tianbao Xie*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hilbert-johnson.github.io/">Siheng Zhao*</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://chenwu.io/">Chen Henry Wu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://yitaoliu17.com/">Yitao Liu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://qianluo.netlify.app/">Qian Luo</a><sup>1</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://www.victorzhong.com/">Victor Zhong</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://yanchaoyang.github.io/">Yanchao Yang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://taoyds.github.io/">Tao Yu</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup>Nanjing University,</span>
            <span class="author-block"><sup>3</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup>4</sup>Microsoft Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://www.xlang.ai/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://www.xlang.ai/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Twitter Link. -->
              <!-- <span class="link-block">
                <a href="https://www.xlang.ai/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-twitter"></i>
                  </span>
                  <span>Twitter</span>
                  </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.xlang.ai/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        An overview of <span class="dnerf">Text2Reward</span> of three stages: <br>
        <em><font color="#228B22">Expert</font> Abstraction</em> provides an abstraction of the environment as a hierarchy of Pythonic classes. <br>
        <em><font color="#4169E1">User</font> Instruction</em> describes the goal to be achieved in natural language.
        <em><font color="#4169E1">User</font> Feedback</em> allows users to summarize the failure mode or their preferences, which are used to improve the reward code.
      </h2>
      <img src="static/images/main.png"> <!-- To .gif format-->
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3">Abstract</h3>
        <div class="content has-text-justified">
          <p>
            Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce <span class="dnerf">Text2Reward</span>, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs). Given a goal described in natural language, <span class="dnerf">Text2Reward</span> generates dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, <span class="dnerf">Text2Reward</span> produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate <span class="dnerf">Text2Reward</span> on two robotic manipulation benchmarks (<span class="dnerf">ManiSkill2</span>, <span class="dnerf">MetaWorld</span>) and two locomotion environments of <span class="dnerf">MuJoCo</span>. On 13 of the 16 manipulation tasks, policies trained with generated reward codes achieve similar or better task success rates and convergence speed than expert-written reward codes. For locomotion tasks, our method learns six novel locomotion behaviors with a success rate exceeding 94%. Furthermore, we show that the policies trained in the simulator with our method can be deployed in the real world. Finally, <span class="dnerf">Text2Reward</span> further improves the policies by refining their reward functions with human feedback. 
          </p>
          <p></p>
        </div>
      </div>
    </div>
  </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-fifths">
        <h3 class="title is-3">Video</h3>
        <p>Coming soon!</p>
        <!-- <div class="publication-video">
          <iframe src="" width="640" height="400" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
        </div> -->
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3">Single-turn Results</h3>
        <div class="content has-text-justified">
          <p>
            We conduct systematic experiments on
          </p>
          <ul>
            <li>two robotics manipulation benchmarks <span class="dnerf">ManiSkill2</span> and <span class="dnerf">MetaWorld</span></li>
            <li>two locomotion environments (Hopper and Ant) of <span class="dnerf">MuJoCo</span></li>
            <li>two tasks (PickCube and StackCube) on a real 7-DoF Franka Panda robot</li>
          </ul>
          <h4 class="title is-4" align="left">Manipulation</h4>
          <p> <strong><span class="dnerf">Text2Reward</span> &#8776 expert-designed rewards on manipulation tasks.</strong> On 13 of the 16 tasks, the final performance (i.e., success rate after convergence and convergence speed) of <span class="dnerf">Text2Reward</span> achieves comparable results to the human oracle. 
            Surprisingly, on 4 of the 16 tasks, zero-shot and few-shot <span class="dnerf">Text2Reward</span> can even outperform human oracle, in terms of either the convergence speed (e.g., Open Cabinet Door in <span class="dnerf">ManiSkill2</span>, Handle Press in <span class="dnerf">MetaWorld</span>) or the success rate (e.g., Pick Cube in <span class="dnerf">ManiSkill2</span>, Drawer Open in <span class="dnerf">MetaWorld</span>).
          </p>
          <img src="static/images/maniskill.png">
          <p></p>
          <img src="static/images/metaworld.png">
          <p></p>

          <section class="hero is-light is-small">
            <div class="hero-body">
              <div class="container">
                <div id="results-carousel" class="carousel results-carousel">

                  <div class="item item-opendrawer">
                    <video poster="" id="opendrawer" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/opendrawer.mp4"
                              type="video/mp4">
                    </video>
                  </div>

                  <div class="item item-buttonpress">
                    <video poster="" id="buttonpress" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/button-press.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-doorclose">
                    <video poster="" id="doorclose" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/door-close.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-draweropen">
                    <video poster="" id="draweropen" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/drawer-open.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-drawerclose">
                    <video poster="" id="drawerclose" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/drawer-close.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-sweepinto">
                    <video poster="" id="sweepinto" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/sweep-into.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-windowclose">
                    <video poster="" id="windowclose" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/window-close.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-windowopen">
                    <video poster="" id="windowopen" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/window-open.mp4"
                              type="video/mp4">
                    </video>
                  </div>

                  <div class="item item-pickcube">
                    <video poster="" id="pickcube" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/pickcube.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-turnfaucet">
                    <video poster="" id="turnfaucet" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/turnfaucet.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-opendoor">
                    <video poster="" id="opendoor" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/opendoor.mp4"
                              type="video/mp4">
                    </video>
                  </div>

                </div>
              </div>
            </div>
          </section>
          <p></p>
          <p>Furthermore, as illustrated in Figure 2, the <span class="dnerf">ManiSkill2</span> data reveals that on 2 of the 6 tasks that are not fully solvable, the few-shot paradigm markedly outperforms the zero-shot approach.</p>
          <div class="columns is-centered">
            <!-- Visual Effects. -->
            <div class="column">
              <div class="content">
                <h6 class="title is-6">Push Chair (zero-shot)</h6>
                <p><font color="red">Fail ❌</font></p>
                <video id="zeroshot-video" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos/zeroshot-PushChair.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
            <div class="column">
              <h6 class="title is-6">Push Chair (few-shot)</h6>
              <p><font color="green">Succeed ✅</font></p>
              <div class="columns is-centered">
                <div class="column content">
                  <video id="fewshot-video" autoplay controls muted loop playsinline height="100%">
                    <source src="./static/videos/fewshot-PushChair.mp4"
                            type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
          </div>

          <h4 class="title is-4" align="left">Locomotion</h4>
          <p><strong><span class="dnerf">Text2Reward</span> can learn novel locomotion behaviors.</strong> Corresponding video results are shown below. The results suggest that our method can generate dense reward functions for
            RL training that generalize to novel locomotion tasks.</p>
          <section class="hero is-light is-small">
            <div class="hero-body">
              <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                  <div class="item item-backflip">
                    <video poster="" id="backflip" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/backflip.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-frontflip">
                    <video poster="" id="frontflip" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/frontflip.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-hoppermove">
                    <video poster="" id="hoppermove" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/hopper-move.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-liedown">
                    <video poster="" id="liedown" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/liedown.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-swing">
                    <video poster="" id="swing" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/swing.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-antmove">
                    <video poster="" id="antmove" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/ant-move.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
            </div>
          </section>
          
          <p></p>
          <h4 class="title is-4" align="left">Real Robot</h4>
          <p><strong><span class="dnerf">Text2Reward</span> &#8594; real robot.</strong> The RL policy trained in the simulator using dense reward function generated from <span class="dnerf">Text2Reward</span> can be successfully deployed to the real world.</p>
          <section class="hero is-light is-small">
            <div class="hero-body">
              <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                  <div class="item item-realstack1">
                    <video poster="" id="realstack1" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/real-stack1.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-realstack2">
                    <video poster="" id="realstack2" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/real-stack2.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-realpick1">
                    <video poster="" id="realpick1" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/real-pick1.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                  <div class="item item-realpick2">
                    <video poster="" id="realpick2" autoplay controls muted loop playsinline height="100%">
                      <source src="./static/videos/real-pick2.mp4"
                              type="video/mp4">
                    </video>
                  </div>
                </div>
              </div>
            </div>
          </section>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3">Interactive Results</h3>
        <div class="content has-text-justified">
          <p>
            <strong><span class="dnerf">Text2Reward</span> can resolve ambiguity from human feedback.</strong> 
            We show one case in which "control the Ant to lie down" itself has ambiguity in terms of the orientation of the Ant, as shown in Figure 6. 
            After observing the training result of this instruction, the user can give the feedback in natural language, e.g., "the Ant's torso should be top down, not bottom up". 
            Then <span class="dnerf">Text2Reward</span> will regenerate the reward code and train a new policy, which successfully caters to the user's intent.
          </p>
          <p></p>
          <img src="static/images/interactive1.png">
          <p></p>
          

          <p>
            <strong><span class="dnerf">Text2Reward</span> can improve RL training from human feedback.</strong>  
            Sometimes single-turn generation can not generate good enough reward functions to finish the task. 
            In these cases, <span class="dnerf">Text2Reward</span> asks for human feedback on the failure mode and tries to improve the dense reward. 
            In Figure 7, we demonstrate this on the Stack Cube task, where zero-shot and few-shot generation in a single turn fails to solve the task stably. 
            For few-shot generation, we observed that interactive code generation with human feedback can improve the success rate from zero to one.
          </p>
          <p></p>
          <img src="static/images/interactive2.png">
          <p></p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Examples. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3"><span class="dnerf">Text2Reward</span> Reward Code Samples</h3>
      </div>
    </div>
  </div>
    <!--/ Examples. -->
</section>

<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>We thank <a href="https://yaomarkmu.github.io/" target="_blank" rel="noopener noreferrer">Yao Mu</a> for the discussions during the early stage before this project.
      We equally thank <a href="https://leili.site/" target="_blank" rel="noopener noreferrer">Lei Li</a> for his feedback!</p>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xie2023text2reward,
  title={Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning},
  author={Xie, Tianbao and Zhao, Siheng and Wu, Chen Henry and Liu, Yitao and Luo, Qian and Zhong, Victor and Yang, Yanchao and Yu, Tao},
  journal={arXiv preprint arXiv:2309},
  year={2023}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://www.xlang.ai/">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://www.xlang.ai/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>